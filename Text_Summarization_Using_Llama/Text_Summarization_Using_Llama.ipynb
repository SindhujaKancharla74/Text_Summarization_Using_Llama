{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import login\n",
    "\n",
    "# Replace 'your_token_here' with your actual Hugging Face token\n",
    "#login(\"your_token_here\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Load the LLaMA model and tokenizer\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"  # Use LLaMA 2 model\n",
    "\n",
    "# Tokenizer and model initialization\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Function for text summarization\n",
    "def summarize_text(text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate the summary (Note: LLaMA is not fine-tuned for summarization)\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, num_beams=4, early_stopping=True)\n",
    "    \n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example text to summarize\n",
    "text_to_summarize = \"\"\"\n",
    "LLaMA (Large Language Model Meta AI) is a family of foundational language models developed by Meta. \n",
    "These models are designed to be efficient and scalable, with versions ranging from 7 billion to 70 billion parameters. \n",
    "The LLaMA models have been trained on publicly available datasets and have shown state-of-the-art performance in various NLP benchmarks. \n",
    "They are intended for researchers and developers to experiment with and apply in different applications, such as text generation, summarization, and question answering.\n",
    "\"\"\"\n",
    "\n",
    "# Get summary\n",
    "summary = summarize_text(text_to_summarize)\n",
    "print(\"Summary:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
